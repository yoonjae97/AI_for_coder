{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5411,"status":"ok","timestamp":1678536718016,"user":{"displayName":"황윤재","userId":"11698835300830029658"},"user_tz":-540},"id":"ySqG_CZzlRwI"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":804},"executionInfo":{"elapsed":988291,"status":"error","timestamp":1678538116627,"user":{"displayName":"황윤재","userId":"11698835300830029658"},"user_tz":-540},"id":"NsBVQf56lTrN","outputId":"47a15797-cffe-4f7c-89c5-6d10f152f171"},"outputs":[],"source":["data = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels), (test_images, test_labels) = data.load_data()\n","\n","training_images = training_images.reshape(60000, 28, 28, 1)\n","training_images = training_images / 255.0\n","\n","test_images = test_images.reshape(10000, 28, 28, 1)\n","test_images = test_images / 255.0\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu',\n","                           input_shape = (28, 28, 1)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation = tf.nn.relu),\n","    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n","])\n","\n","model.compile(optimizer = 'adam',\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics = ['accuracy'])\n","\n","model.fit(training_images, training_labels, epochs = 50)\n","\n","model.evaluate(test_images, test_labels)\n","\n","classifications = model.predict(test_images)\n","\n","print(classifications[0])\n","print(test_labels[0])"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2485,"status":"ok","timestamp":1678538427887,"user":{"displayName":"황윤재","userId":"11698835300830029658"},"user_tz":-540},"id":"o9-MIlHPq0wa"},"outputs":[],"source":["import urllib.request\n","import zipfile\n","\n","url = \"https://storage.googleapis.com/learning-datasets/horse-or-human.zip\"\n","file_name = \"horse-or-human.zip\"\n","training_dir = 'horse-or-human/training/'\n","urllib.request.urlretrieve(url, file_name)\n","\n","zip_ref = zipfile.ZipFile(file_name, 'r')\n","zip_ref.extractall(training_dir)\n","zip_ref.close()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":360,"status":"ok","timestamp":1678538487134,"user":{"displayName":"황윤재","userId":"11698835300830029658"},"user_tz":-540},"id":"Y-1UEUW2rOvC","outputId":"3641d4ec-8d65-4150-adfe-c725d5eec2a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1027 images belonging to 2 classes.\n"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# 전체 이미지를 1./255로 스케일을 조정합니다.\n","train_datagen = ImageDataGenerator(rescale=1/255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    training_dir,\n","    target_size=(300, 300),\n","    class_mode='binary'\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":307,"status":"ok","timestamp":1678538651045,"user":{"displayName":"황윤재","userId":"11698835300830029658"},"user_tz":-540},"id":"Rq8AMQ47sLDN"},"outputs":[],"source":["# training_ds = tf.keras.utils.image_dataset_from_directory(\n","#     training_dir,\n","#     image_size = (300, 300),\n","#     label_mode = 'binary'\n","# )\n","\n","# ImageDataGenerator 대신 image_dataset_from_directory 사용할 경우 전처리 따로 필요\n","\n","model = tf.keras.models.Sequential([\n","    # tf.keras.layers.Rescaling(1. / 255, input_shape = (300, 300, 3)),\n","    tf.keras.layers.Conv2D(16, (3, 3), activation = 'relu',\n","                           input_shape = (300, 300, 3)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","\n","    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu',\n","                           input_shape = (300, 300, 3)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","\n","    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu',\n","                           input_shape = (300, 300, 3)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","\n","    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu',\n","                           input_shape = (300, 300, 3)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","\n","    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu',\n","                           input_shape = (300, 300, 3)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation = 'relu'),\n","    tf.keras.layers.Dense(1, activation = 'sigmoid')\n","\n","])"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1678538657860,"user":{"displayName":"황윤재","userId":"11698835300830029658"},"user_tz":-540},"id":"KAnAqhcUsznB","outputId":"003aefc5-bd55-45e6-e6e7-8094acfdd522"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 298, 298, 16)      448       \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 149, 149, 16)     0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 147, 147, 32)      4640      \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 73, 73, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 71, 71, 64)        18496     \n","                                                                 \n"," max_pooling2d_6 (MaxPooling  (None, 35, 35, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 33, 33, 64)        36928     \n","                                                                 \n"," max_pooling2d_7 (MaxPooling  (None, 16, 16, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 14, 14, 64)        36928     \n","                                                                 \n"," max_pooling2d_8 (MaxPooling  (None, 7, 7, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_2 (Flatten)         (None, 3136)              0         \n","                                                                 \n"," dense_4 (Dense)             (None, 512)               1606144   \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 1,704,097\n","Trainable params: 1,704,097\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":302,"status":"ok","timestamp":1678538749441,"user":{"displayName":"황윤재","userId":"11698835300830029658"},"user_tz":-540},"id":"qmpqwcSgs00U"},"outputs":[],"source":["from tensorflow.keras.optimizers import RMSprop\n","\n","model.compile(loss = 'binary_crossentropy',\n","              optimizer = RMSprop(learning_rate = 0.001),\n","              metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p04PreTutLGy","outputId":"f0daa85e-645d-4fa2-8609-b35c871e2423"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","33/33 [==============================] - 118s 4s/step - loss: 0.7187 - accuracy: 0.5901\n","Epoch 2/15\n","33/33 [==============================] - 108s 3s/step - loss: 0.5370 - accuracy: 0.8393\n","Epoch 3/15\n","33/33 [==============================] - 107s 3s/step - loss: 0.2963 - accuracy: 0.8812\n","Epoch 4/15\n","33/33 [==============================] - 126s 4s/step - loss: 0.2307 - accuracy: 0.9104\n","Epoch 5/15\n","33/33 [==============================] - 146s 4s/step - loss: 0.1197 - accuracy: 0.9542\n"]}],"source":["model.fit(train_generator, epochs = 15)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rrLM23DjtOtx"},"outputs":[],"source":["validation_url = \"https://storage.googleapis.com/learning-datasets/validation-horse-or-human.zip\"\n","\n","validation_file_name = \"validation-horse-or-human.zip\"\n","validation_dir = 'horse-or-human/validation/'\n","urllib.request.urlretrieve(validation_url, validation_file_name)\n","\n","zip_ref = zipfile.ZipFile(validation_file_name, 'r')\n","zip_ref.extractall(validation_dir)\n","zip_ref.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7AIKi376vnVI"},"outputs":[],"source":["validation_datagen = ImageDataGenerator(rescale = 1 / 255)\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    validation_dir,\n","    target_size = (300, 300),\n","    class_mode = 'binary'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Pb38Qj1vylk"},"outputs":[],"source":["model.fit(train_generator,\n","          epochs = 15,\n","          validation_data = validation_generator)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7Y_uu2TiwCNp"},"source":["## 추가로 공부가 필요한 내용\n","- CNN 합성곱 신경망의 기본적인 구조 ex. filter, padding, stride, pooling\n","- ImageDataGenerator, image_dataset_from_directory 비교"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMpCzagBdVxB5wHYhTeiG1J","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
